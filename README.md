# HAIA - Homelab AI Assistant

A standalone AI assistant application for homelab administration, monitoring, and troubleshooting. Built with PydanticAI and powered by local LLMs via Ollama. Exposes an OpenWebUI-compatible API for chat-based interaction.

## Features

- ğŸ–¥ï¸ **Infrastructure Monitoring**: Track Proxmox VMs, containers, and services
- ğŸš¨ **Proactive Alerts**: Get notified about problems before they escalate
- ğŸ”§ **Troubleshooting Assistance**: AI-powered suggestions for common issues
- ğŸ  **Home Assistant Integration**: Control and query your smart home
- ğŸ”Œ **Extensible via MCP**: Add new capabilities through Model Context Protocol servers

## Quick Start

### Prerequisites

- Python 3.11+
- Anthropic API key (for development) or Ollama (for production)
- Access to your homelab APIs (Proxmox, Home Assistant, etc.)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/haia.git
cd haia

# Install with uv (recommended)
uv sync

# Or with pip
pip install -e .
```

### Configuration

```bash
# Copy the example environment file
cp .env.example .env

# Edit with your configuration
# - ANTHROPIC_API_KEY (for development)
# - HAIA_MODEL=anthropic:claude-haiku-4-5-20251001 (or ollama:qwen2.5-coder for local)
# - PROXMOX_HOST, PROXMOX_USER, PROXMOX_TOKEN
# - HOMEASSISTANT_URL, HOMEASSISTANT_TOKEN
```

### Running

```bash
# Start the API server (OpenWebUI-compatible)
haia serve

# The API will be available at http://localhost:8000
# Compatible with OpenWebUI - point it to http://localhost:8000/v1
```

## Architecture

HAIA is a **standalone application** that runs as an API server, compatible with OpenWebUI and other OpenAI-compatible frontends.

**Core Components:**

- **PydanticAI** - Agent framework with type-safe tool definitions
- **FastAPI** - OpenAI-compatible API endpoints
- **MCP Servers** - Extensible, standardized tool integration
- **Ollama** - Local LLM inference (or Anthropic for development)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OpenWebUI / Chat Interface           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP (OpenAI-compatible API)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Server (/v1/chat)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         HAIA Agent (PydanticAI)              â”‚
â”‚   Model: configurable (Anthropic/Ollama)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Tools                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Custom Tools    â”‚  â”‚ MCP Servers      â”‚   â”‚
â”‚  â”‚ @agent.tool     â”‚  â”‚ (via toolsets)   â”‚   â”‚
â”‚  â”‚ - Proxmox ops   â”‚  â”‚ - Filesystem     â”‚   â”‚
â”‚  â”‚ - HA integrationâ”‚  â”‚ - Docker         â”‚   â”‚
â”‚  â”‚ - Alerting      â”‚  â”‚ - Prometheus     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Background: Scheduler (APScheduler)      â”‚
â”‚        - Periodic infrastructure checks      â”‚
â”‚        - Proactive alerting                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## MCP Servers

HAIA can connect to MCP servers for extended functionality. Configure in `mcp_config.json`:

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["@modelcontextprotocol/server-filesystem", "/var/log"]
    }
  }
}
```

## Development

```bash
# Run tests
pytest

# Type checking
mypy src/

# Linting
ruff check src/
```

## License

MIT
