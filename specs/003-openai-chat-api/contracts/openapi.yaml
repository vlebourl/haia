openapi: 3.1.0
info:
  title: HAIA Chat API
  version: 1.0.0
  description: |
    OpenAI-compatible Chat Completions API for HAIA (Homelab AI Assistant).

    This API implements a subset of the OpenAI Chat Completions API v1 for
    compatibility with OpenWebUI and other OpenAI-compatible clients.

    **Key Features**:
    - Streaming responses via Server-Sent Events (SSE)
    - Non-streaming JSON responses
    - Persistent conversation history
    - 20-message context window
    - Multi-provider support (Anthropic, Ollama)
  contact:
    name: HAIA
    url: https://github.com/vlebourl/haia

servers:
  - url: http://localhost:8000
    description: Local development server
  - url: http://haia.local:8000
    description: Homelab deployment

paths:
  /v1/chat/completions:
    post:
      summary: Create chat completion
      description: |
        Generate a chat completion with optional streaming support.

        **Non-streaming**: Returns complete response as JSON
        **Streaming**: Returns Server-Sent Events (SSE) with incremental chunks

        Conversations are automatically persisted with 20-message context window.
      operationId: createChatCompletion
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              simple_query:
                summary: Simple question
                value:
                  messages:
                    - role: user
                      content: Hello, what can you help me with?
                  stream: false
              streaming_query:
                summary: Streaming response
                value:
                  messages:
                    - role: user
                      content: Explain how to set up Proxmox VE cluster
                  stream: true
                  temperature: 0.7
                  max_tokens: 2048
      responses:
        '200':
          description: Successful chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
              examples:
                successful_response:
                  summary: Successful completion
                  value:
                    id: conv_abc123
                    object: chat.completion
                    created: 1701000000
                    model: anthropic:claude-haiku-4-5-20251001
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: I can help you with homelab infrastructure...
                        finish_reason: stop
                    usage:
                      prompt_tokens: 15
                      completion_tokens: 42
                      total_tokens: 57
            text/event-stream:
              schema:
                type: string
                description: Server-Sent Events stream of ChatCompletionChunk
              examples:
                streaming_response:
                  summary: SSE streaming chunks
                  value: |
                    data: {"id":"conv_abc123","object":"chat.completion.chunk","created":1701000000,"model":"anthropic:claude-haiku-4-5-20251001","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

                    data: {"id":"conv_abc123","object":"chat.completion.chunk","created":1701000000,"model":"anthropic:claude-haiku-4-5-20251001","choices":[{"index":0,"delta":{"content":"I"},"finish_reason":null}]}

                    data: {"id":"conv_abc123","object":"chat.completion.chunk","created":1701000000,"model":"anthropic:claude-haiku-4-5-20251001","choices":[{"index":0,"delta":{"content":" can"},"finish_reason":null}]}

                    data: {"id":"conv_abc123","object":"chat.completion.chunk","created":1701000000,"model":"anthropic:claude-haiku-4-5-20251001","choices":[{"index":0,"delta":{},"finish_reason":"stop"}],"usage":{"prompt_tokens":15,"completion_tokens":42,"total_tokens":57}}

                    data: [DONE]
        '400':
          description: Bad request - Invalid input
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              examples:
                empty_messages:
                  summary: Empty messages array
                  value:
                    error:
                      message: Messages array cannot be empty
                      type: validation_error
                      code: invalid_request
        '401':
          description: Unauthorized - Invalid API key
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              examples:
                invalid_api_key:
                  summary: Invalid API key
                  value:
                    error:
                      message: Invalid API key provided
                      type: authentication_error
                      code: invalid_api_key
        '429':
          description: Rate limit exceeded
          headers:
            Retry-After:
              description: Seconds to wait before retrying
              schema:
                type: integer
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              examples:
                rate_limit:
                  summary: Rate limit hit
                  value:
                    error:
                      message: Rate limit exceeded. Please retry after 60 seconds.
                      type: rate_limit_error
                      code: rate_limit_exceeded
        '503':
          description: Service unavailable - LLM provider down
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              examples:
                llm_unavailable:
                  summary: LLM service down
                  value:
                    error:
                      message: AI service temporarily unavailable. Please try again later.
                      type: service_unavailable_error
                      code: llm_unavailable

  /health:
    get:
      summary: Health check
      description: Check if the API server is running and ready
      operationId: healthCheck
      tags:
        - System
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    enum: [healthy]
                  timestamp:
                    type: integer
                    description: Unix timestamp
                example:
                  status: healthy
                  timestamp: 1701000000

components:
  schemas:
    ChatMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant]
          description: Role of the message sender
        content:
          type: string
          minLength: 1
          description: Content of the message
      example:
        role: user
        content: What VMs are running?

    ChatCompletionRequest:
      type: object
      required:
        - messages
      properties:
        messages:
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/ChatMessage'
          description: List of messages in the conversation
        model:
          type: string
          description: Model to use (optional, uses HAIA_MODEL from config)
          example: anthropic:claude-haiku-4-5-20251001
        temperature:
          type: number
          minimum: 0.0
          maximum: 2.0
          default: 0.7
          description: Sampling temperature
        max_tokens:
          type: integer
          minimum: 1
          maximum: 4096
          default: 1024
          description: Maximum tokens to generate
        stream:
          type: boolean
          default: false
          description: Whether to stream the response via SSE
        top_p:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: Nucleus sampling parameter (optional)
        frequency_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          description: Frequency penalty (optional)
        presence_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          description: Presence penalty (optional)
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: Stop sequences (optional)
        n:
          type: integer
          minimum: 1
          description: Number of completions (optional, currently only n=1 supported)
      example:
        messages:
          - role: user
            content: Hello, what can you help me with?
        temperature: 0.7
        max_tokens: 1024
        stream: false

    TokenUsage:
      type: object
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          minimum: 0
          description: Tokens in the prompt
        completion_tokens:
          type: integer
          minimum: 0
          description: Tokens in the completion
        total_tokens:
          type: integer
          minimum: 0
          description: Total tokens used
      example:
        prompt_tokens: 15
        completion_tokens: 42
        total_tokens: 57

    Choice:
      type: object
      required:
        - index
        - message
      properties:
        index:
          type: integer
          description: Choice index (always 0)
        message:
          $ref: '#/components/schemas/ChatMessage'
        finish_reason:
          type: string
          enum: [stop, length, error]
          description: Reason for completion termination
      example:
        index: 0
        message:
          role: assistant
          content: I can help you with homelab infrastructure...
        finish_reason: stop

    ChatCompletionResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
        - usage
      properties:
        id:
          type: string
          description: Conversation ID
        object:
          type: string
          enum: [chat.completion]
          description: Object type
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for completion
        choices:
          type: array
          items:
            $ref: '#/components/schemas/Choice'
          description: Completion choices
        usage:
          $ref: '#/components/schemas/TokenUsage'
      example:
        id: conv_abc123
        object: chat.completion
        created: 1701000000
        model: anthropic:claude-haiku-4-5-20251001
        choices:
          - index: 0
            message:
              role: assistant
              content: I can help you with homelab infrastructure...
            finish_reason: stop
        usage:
          prompt_tokens: 15
          completion_tokens: 42
          total_tokens: 57

    MessageDelta:
      type: object
      properties:
        role:
          type: string
          enum: [system, user, assistant]
          description: Role (only in first chunk)
        content:
          type: string
          description: Incremental content
      example:
        content: I can

    ChoiceDelta:
      type: object
      required:
        - index
        - delta
      properties:
        index:
          type: integer
          description: Choice index
        delta:
          $ref: '#/components/schemas/MessageDelta'
        finish_reason:
          type: string
          enum: [stop, length, error]
          description: Finish reason (only in final chunk)
      example:
        index: 0
        delta:
          content: I can
        finish_reason: null

    ChatCompletionChunk:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: Conversation ID
        object:
          type: string
          enum: [chat.completion.chunk]
          description: Object type
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChoiceDelta'
          description: Choice deltas
        usage:
          $ref: '#/components/schemas/TokenUsage'
          description: Usage statistics (only in final chunk)
      example:
        id: conv_abc123
        object: chat.completion.chunk
        created: 1701000000
        model: anthropic:claude-haiku-4-5-20251001
        choices:
          - index: 0
            delta:
              content: I can
            finish_reason: null
        usage: null

    ErrorDetail:
      type: object
      required:
        - message
        - type
      properties:
        message:
          type: string
          description: Human-readable error message
        type:
          type: string
          description: Error type identifier
        code:
          type: string
          description: Error code
      example:
        message: Invalid API key provided
        type: authentication_error
        code: invalid_api_key

    ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          $ref: '#/components/schemas/ErrorDetail'
      example:
        error:
          message: Invalid API key provided
          type: authentication_error
          code: invalid_api_key

tags:
  - name: Chat
    description: Chat completion endpoints
  - name: System
    description: System health and monitoring
